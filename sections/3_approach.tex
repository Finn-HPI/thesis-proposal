\section{Approach}
\label{sec:approach}

% Methodological and conceptual approach of the thesis and ideas/plans of implementation.

The sort-merge join involves sorting both input relations by the join attribute. It is the most crucial and 
time-consuming part of the sort-merge join operation. Therefore, high optimization efforts should
be spend on this step, as it largely determines the runtime. 

We chose vectorized mergesort over vectorized quicksort because of the extensive foundational work in 
the literature. Some SIMD quicksort implementations vectorize only the partitioning step \cite{DBLP:journals/cj/GueronK16},
and some newer implementations also use sorting networks using AVX-512 \cite{Bramas}. They often share
similarities then compared to mergesort, such as sorting networks. While it is interesting
to study the differences between vectorized quicksort and merge sort, we will limit ourselves to
mergesort due to the limited time scope.

\subsection{SIMD Data Format}
Before we can sort our input relations, the join attribute values need to be translated into a SIMD sortable
format. Usually, a 64-bit pair (key, rid) is assumed. We, therefore,
support a maximum relation size of $2^{32}$. With most value types greater
than 32 bits, e.g. strings, we need to compress the values of the join columns. Methods like 
key-prefix \cite{chris_nyberg__1994} and XOR- and shift-based hash functions \cite{1319989} have 
been used to generate keys of 32 bits.

As strings are variable in size, it makes sense to consider their internal representation and
encoding. Certain string representations allow for cheap access to a prefix or short string.
For instance, Umbra's string representation \cite{DBLP:conf/cidr/NeumannF20} consists of a 128-bit 
struct and is adopted by more recent databases like CedarDB and DuckDB. The first 32 bits represent 
the length. The remaining bits hold
the complete string if the length is at most 12. Otherwise, the struct consists of the 32-bit
length, a 32-bit prefix, and a pointer to a storage location. Due to saving pointer dereferences,
this can speed up comparison, lexicographical sorting, and other prefix operations.



\subsection{Partitioning}
To make use of the multi-core architecture, the unsorted column data of both join relations are partitioned
into chunks and distributed among the available threads. One option for partitioning is to divide
the unsorted inputs into thread count many contiguous sections of equal size. Using this 
strategy, occurrences of the same value can happen in multiple partitions, always requiring a global
merge over all partitions (even if global sorting is not required). Another option is range partitioning, e.g., through radix partitioning.
We can often improve radix-partitioning through software-managed buffers and non-temporal streaming
stores (for x86 provided by the AVX instruction set) \cite{DBLP:journals/pvldb/SchuhknechtKD15}.
For architectures with non-uniform memory access
(NUMA), it can make sense to distribute equally over NUMA regions and let threads read from their 
closest NUMA region. However, for this thesis, we will keep NUMA optimizations optional.

\subsection{Sorting and Merging}

The sort and merge step aims to sort both input relations based on the join attribute. Usually,
we aim for global sorting, but there might be cases where partial sorting is enough, e.g.,
inside a range partition.

\subsubsection{SIMD Sort- and Merge-Networks}

To efficiently utilize SIMD, we need an algorithm that aligns with the SIMD execution model. 
Sorting and merging networks meet these criteria. 
For a network of input size $n$, $n$ items enter the network from left to right through a series of 
comparators that emit the larger value to the top and the smaller value to the bottom. We can
implement such a network with only min/max operators. The input is in arbitrary order for a 
sorting network, leaving the network sorted. For a merging network, the input comprises two sorted
halves that merge into one sorted list of size n. There are two standard merging network types:
bitonic merge networks and odd-even merge networks \cite{10.14778/1454159.1454171}. 

We can replace each input item with a SIMD vector and use vectorized min/max operations to take
advantage of SIMD. The input items are sorted across SIMD registers, therefore requiring additional
transposition.
Due to the merge networks' poor scaling \cite{DBLP:journals/vldb/MullerTA12}, we can use small merging networks within a merging
algorithm for larger lists \cite{4336211}.


\subsubsection{Merging Higher Levels}

We can merge different subparts of the data in different threads as long as we have enough
sorted sublists. In the later round of the merge tree, with only a few sorted sublists remaining,
parallelizing becomes more challenging. However, parallelization is still possible through
algorithms like Merge Path \cite{MergePath}. This conceptual path allows us to parallelize a two-way
merge by splitting it into non-overlapping segments that form disjoint sets of elements.
We can then merge these segments in parallel. In the later stages, out-of-cache merging becomes
necessary, potentially creating a bottleneck through memory bandwidth limitations. Therefore,
multi-way merging \cite{Balkesen,10.14778/1454159.1454171} solves this problem by saving roundtrips to memory. It implements a 
merge-tree, with each node being a two-way merge unit. The nodes are connected via FIFO queues. 
Only the leave nodes directly access memory. By pausing and starting the execution of nodes,
we always ensure that all combined FIFO queues still fit into the cache. By doing so, we 
step-by-step propagate buffers of merged data through the merge tree until all data is merged.
Optionally, we could explore merging through other primitives, such as
tournament trees or priority queues.

\subsection{Joining}

After sorting both input relations, a final loop over both sorted input relations suffices to find all
join candidates. The sorted data is of the form (key, rid). Hence, we can use the row ID (rid) to
find the respective tuples. As compression can result in false positives in the merging step, we
might require additional validation and 
filtering. Further parallelization of this final join step is also possible.

